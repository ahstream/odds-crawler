

export async function addSeasonsToQueue(divisionCode) {
  divisionCode = utilslib.trimRight(divisionCode, '/');

  log.debug(`Add seasons for division ${divisionCode} to crawler queue`);

  const seasons = await getSeasons(divisionCode);
  if (seasons === null || seasons.length <= 0) {
    return -1;
  }

  const numSeasons = seasons.length;
  let numAdded = 0;

  for (let i = 0; i < numSeasons; i++) {
    const season = seasons[i];
    numAdded = numAdded + crawlerQueue.addSeasonToQueue(divisionCode, season.seasonYear);
  }
  if (numAdded !== numSeasons) {
    log.warn('Added seasons differ from number of seasons!');
  }

  return numAdded;
}



export async function crawlSeasons(divisionCode) {
  divisionCode = utilslib.trimRight(divisionCode, '/');

  log.info(`Start crawling seasons for division: ${divisionCode}`);

  const seasons = await getSeasons(divisionCode);
  if (seasons === null || seasons.length <= 0) {
    return -1;
  }
  const numSeasons = seasons.length;

  let numFailed = 0;

  for (let i = 0; i < numSeasons; i++) {
    const season = seasons[i];
    log.info(`Crawl season ${i + 1} of ${numSeasons}: ${season.seasonYear}`);

    try {
      numFailed = numFailed + (await crawlSeason(divisionCode, season.seasonYear));
    } catch (error) {
      log.error('Catched error:', error, divisionCode, season.seasonYear);
    }
  }

  log.info(`Done crawling seasons!`);

  return numFailed;
}

export async function crawlSeason(divisionCode, year) {
  divisionCode = utilslib.trimRight(divisionCode, '/');

  log.info(`Start crawling season for division: ${divisionCode}, season year: ${year}`);

  const season = await getSeason(divisionCode, year);
  if (season.ok === false) {
    return -1;
  }

  const failedEventUrls = await eventslib.crawlEvents(season.eventUrls, divisionCode, true);
  let numFailed = failedEventUrls.length;

  if (numFailed > 0) {
    log.error(`Failed to crawl ${numFailed} events. These were added to crawler queue. Will run through queue now...`);
    log.verbose('Failed event links:', failedEventUrls);

    numFailed = await crawlerQueue.crawlQueue();
    if (numFailed === 0) {
      log.info(`Finished crawling queue! All items have been crawled successfully!`);
    } else {
      log.info(`Finished crawling queue! ${numFailed} items still left in crawler queue.`);
    }
  }

  log.info(`Done crawling season!`);

  return numFailed;
}

export async function crawlEvents(urlList, divisionCode, options = { addToQueue = true, skipDups = true }) {
  log.debug(`Crawl ${urlList.length} events from ${divisionCode}`);

  const errorUrls = [];
  const numEvents = urlList.length;

  let count = 0;
  for (let i = 0; i < numEvents; i++) {
    count++;
    if (count > config.maxEventsPerSeason) {
      log.info(`Break event crawling after max: ${config.maxEventsPerSeason} of total: ${numEvents} events!`);
      break;
    }

    const eventUrl = urlList[i];
    log.info(`Crawl event ${i + 1} of ${numEvents}: ${eventUrl}`);
    try {
      const event = await crawlEvent(eventUrl, divisionCode, options);
      // todo: handle duplicates!
      if (event.ok !== true) {
        errorUrls.push(eventUrl);
      }
    } catch (error) {
      log.error('Catched error:', error, eventUrl);
      errorUrls.push(eventUrl);
    }
  }

  return errorUrls;
}
